{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape = (224,224,3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 134,301,514\n",
      "Trainable params: 119,586,826\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(4096, name='fc1')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(4096, name='fc2')(x)\n",
    "x = Dense(10, activation=None, name='predictions')(x)\n",
    "\n",
    "\n",
    "model_final = Model(inputs=base_model.input, outputs=x)\n",
    "#model_final.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.sgd(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "model_final.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.RMSprop(lr=0.00001), metrics=[\"accuracy\"])\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n",
      "Found 500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "weights_file = 'vgg16_clothing_classifier.h5'\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                  shear_range =.2,\n",
    "                                  zoom_range = .2,\n",
    "                                  horizontal_flip = True)\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_data_dir = 'subset/train'\n",
    "validation_data_dir = \"subset/test\"\n",
    "nb_validation_samples = 1000\n",
    "nb_train_samples = 5000\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                train_data_dir,\n",
    "                target_size=(img_width, img_height),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical',\n",
    "                shuffle=True)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "                                validation_data_dir,\n",
    "                                target_size = (img_height, img_width),\n",
    "                                batch_size=batch_size,\n",
    "                                class_mode = \"categorical\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(weights_file, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': 0,\n",
       " 'jacket': 1,\n",
       " 'jeans': 2,\n",
       " 'outerwear': 3,\n",
       " 'pants': 4,\n",
       " 'shorts': 5,\n",
       " 'skirts': 6,\n",
       " 'sweaters': 7,\n",
       " 'sweatshirt': 8,\n",
       " 'tops': 9}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2/312 [..............................] - ETA: 1:27:49 - loss: 6.8676 - acc: 0.0938    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-96aa52393edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             callbacks = [checkpoint, early])\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "history = model_final.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples//batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=nb_validation_samples//batch_size,\n",
    "            verbose=1,\n",
    "            workers=4,\n",
    "            callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182140eac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.save_weights(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "def get_input(img_path):\n",
    "    img = imread(img_path)\n",
    "    img = resize(img, (224, 224), preserve_range=True).astype(np.float32)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def get_predictions(img_path, decode=True):\n",
    "    input_ = get_input(img_path)\n",
    "    out = model_final.predict(input_)\n",
    "    if decode:\n",
    "        return decode_predictions(out)\n",
    "    else:\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 41.26117  , -38.70192  ,  34.237724 , -18.751616 ,  51.80874  ,\n",
       "         -6.1047664, -37.319256 ,  18.213902 ,   9.048164 ,   8.462398 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.predict(get_input('data/train/sweatshirt/693270349.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pre_process(img_file):\n",
    "    img = imread(img_file)\n",
    "    img = resize(img, (224, 224), preserve_range=True).astype(np.float32)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         ...,\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ]],\n",
       "\n",
       "        [[151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         ...,\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ]],\n",
       "\n",
       "        [[151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         ...,\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         ...,\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ]],\n",
       "\n",
       "        [[150.061  , 137.22101, 130.32   ],\n",
       "         [150.061  , 137.22101, 130.32   ],\n",
       "         [150.061  , 137.22101, 130.32   ],\n",
       "         ...,\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ]],\n",
       "\n",
       "        [[149.66367, 136.82367, 129.92267],\n",
       "         [149.66367, 136.82367, 129.92267],\n",
       "         [149.66367, 136.82367, 129.92267],\n",
       "         ...,\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ],\n",
       "         [151.061  , 138.22101, 131.32   ]]]], dtype=float32)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_pre_process('data/train/pants/202176513.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "img = image_pre_process('data/train/pants/202176513.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (train_generator.class_indices)\n",
    "label_map = dict((v,k) for k,v in label_map.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pants'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions= model_final.predict(img)[0]\n",
    "predictions = np.argmax(predictions,axis=-1)\n",
    "predictions = label_map[predictions]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': 0,\n",
       " 'jacket': 1,\n",
       " 'jeans': 2,\n",
       " 'outerwear': 3,\n",
       " 'pants': 4,\n",
       " 'shorts': 5,\n",
       " 'skirts': 6,\n",
       " 'sweaters': 7,\n",
       " 'sweatshirt': 8,\n",
       " 'tops': 9}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
